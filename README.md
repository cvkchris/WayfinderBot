# ğŸ¤– WayfinderBot - Warehouse Navigation using Reinforcement Learning

WayfinderBot is a grid-based warehouse navigation simulation using Q-Learning. The bot learns to navigate efficiently from start to goal while avoiding obstacles (walls). It also visualizes the learned Q-values using heatmaps and tracks agent performance.

---

## ğŸš€ Project Overview

This project implements:
- A **grid world environment** simulating warehouse navigation
- **Q-learning** algorithm for training the agent
- Reward and penalty system for optimal path finding
- **Seaborn heatmaps** to visualize learned Q-values
- Easy-to-understand simulation and configuration

---

## ğŸ§  Core Features

| Feature                  | Description |
|--------------------------|-------------|
| `learning_process.py`    | Handles the Q-learning logic and training |
| `main.py`                | Visualizes the navigation and agent decisions |
| `q_values.npy`           | Stores the learned Q-table |
| ğŸ“Š Heatmaps              | Generated to understand learned behavior |
| ğŸ§­ Goal, Wall, and Path  | Visual cues in environment |
| ğŸ’¾ Configurable          | Change learning rate, gamma, epsilon easily |

---

## ğŸ—‚ï¸ Project Structure
```
WayfinderBot/
â”œâ”€â”€ warehouserobot/
â”‚   â”œâ”€â”€ learning_process.py      # Q-learning training logic
â”‚   â”œâ”€â”€ main.py                  # Environment setup and simulation
â”‚   â”œâ”€â”€ q_values.npy             # Saved Q-table (after training)
â”‚   â””â”€â”€ __init__.py              # (optional) makes it a Python package
â”œâ”€â”€ requirements.txt             # Python dependencies
â””â”€â”€ README.md                    # Project documentation
```

---

## ğŸ—ï¸ How to Run

1. **Install dependencies**
    ```bash
    pip install -r requirements.txt
    ```

2. **Train the bot**
    ```bash
    python warehouserobot/learning_process.py
    ```

3. **Run the main simulation**
    ```bash
    python warehouserobot/main.py
    ```

---

## ğŸ“‰ Training Configuration (Default)

| Parameter         | Value  |
|------------------|--------|
| Episodes          | 1000   |
| Learning Rate     | 0.9    |
| Discount Factor Î³ | 0.9    |
| Exploration Rate Îµ| 0.9    |

---

## ğŸ† Reward System

| Scenario       | Reward   |
|----------------|----------|
| Reaching Goal  | +100     |
| Moving Freely  | -1       |
| Hitting a Wall | -100     |

---

